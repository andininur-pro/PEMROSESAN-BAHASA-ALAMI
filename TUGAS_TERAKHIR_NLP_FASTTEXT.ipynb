{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#FASTTEXT"
      ],
      "metadata": {
        "id": "gMV9ssUFr7eG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchtext\n",
        "!pip install torch==2.0.0\n",
        "!pip install torchtext==0.15.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZAgkSuD_Jy2",
        "outputId": "ba17dc20-7907-480b-d6d7-46874f041866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.0.0\n",
            "  Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchtext==0.15.2\n",
            "  Using cached torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (2.32.3)\n",
            "Collecting torch==2.0.1 (from torchtext==0.15.2)\n",
            "  Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.2) (1.26.4)\n",
            "Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n",
            "  Using cached torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext==0.15.2) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.30.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.2) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n",
            "Using cached torchtext-0.15.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "Using cached torchdata-0.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0\n",
            "    Uninstalling torch-2.0.0:\n",
            "      Successfully uninstalled torch-2.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import Vectors, build_vocab_from_iterator\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Load spaCy tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, vocab):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.data.iloc[idx]['text']\n",
        "        label = self.data.iloc[idx]['label']\n",
        "        tokens = self.tokenizer(text)\n",
        "        token_ids = [self.vocab[token] for token in tokens]\n",
        "        return torch.tensor(token_ids, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Padding and collate_fn function\n",
        "def collate_batch(batch):\n",
        "    # Padding sequence data\n",
        "    text, labels = zip(*batch)\n",
        "    text = pad_sequence(text, padding_value=0, batch_first=True)  # Padding dengan 0\n",
        "    labels = torch.tensor(labels)\n",
        "    return text, labels\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv(\"/content/trainn.csv\", sep=\";\")\n",
        "test_df = pd.read_csv(\"/content/testt.csv\", sep=\";\")\n",
        "train_df = train_df.drop(train_df.columns[3:61], axis=1)\n",
        "test_df = test_df.drop(test_df.columns[3:61], axis=1)\n",
        "\n",
        "train_df['text'] = train_df['text1'] + ' ' + train_df['text2']\n",
        "test_df['text'] = test_df['text1'] + ' ' + test_df['text2']\n",
        "\n",
        "# Pastikan kolom 'text' adalah string dan ganti NaN dengan string kosong\n",
        "train_df['text'] = train_df['text'].fillna('').astype(str)\n",
        "test_df['text'] = test_df['text'].fillna('').astype(str)\n",
        "\n",
        "# Tokenize the text column and build vocab\n",
        "train_tokens = [tokenizer(text) for text in train_df['text']]\n",
        "vocab = build_vocab_from_iterator(train_tokens, specials=['<unk>', '<pad>'])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# Load GloVe vectors (glove.6B.100d.txt)\n",
        "glove_vectors = Vectors(name=\"glove.6B.100d.txt\")\n",
        "\n",
        "# FastText Model with GloVe Embeddings\n",
        "class FastText(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, output_dim, pad_idx, vectors=None):\n",
        "        super(FastText, self).__init__()\n",
        "\n",
        "        # Inisialisasi embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
        "\n",
        "        if vectors is not None:\n",
        "            # Inisialisasi embedding layer dengan vektor GloVe\n",
        "            pretrained_embeddings = torch.zeros(vocab_size, embed_dim)\n",
        "\n",
        "            # Memetakan GloVe vektor ke vocab yang ada\n",
        "            for i, token in enumerate(vocab.get_itos()):  # vocab.get_itos() memberikan urutan kata\n",
        "                if token in vectors.stoi:  # Cek apakah token ada di dalam vocab GloVe\n",
        "                    pretrained_embeddings[i] = vectors[token]\n",
        "\n",
        "            # Salin embeddings yang sudah terisi ke embedding layer\n",
        "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "            self.embedding.weight.requires_grad = False  # Nonaktifkan pembaruan bobot embedding\n",
        "\n",
        "        self.fc = nn.Linear(embed_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # Proses teks melalui embedding layer\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # Mean pooling untuk menghasilkan representasi vektor per kalimat\n",
        "        pooled = embedded.mean(dim=1)\n",
        "\n",
        "        # Lanjutkan ke layer fully connected\n",
        "        return self.fc(pooled)\n",
        "\n",
        "\n",
        "# Parameters\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 100  # GloVe 6B 100 dimensi\n",
        "output_dim = 5\n",
        "pad_idx = vocab['<pad>']\n",
        "\n",
        "# Initialize the model with GloVe vectors\n",
        "model = FastText(vocab_size, embed_dim, output_dim, pad_idx, vectors=glove_vectors)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TextDataset(train_df, tokenizer, vocab)\n",
        "test_dataset = TextDataset(test_df, tokenizer, vocab)\n",
        "\n",
        "# Create DataLoader with collate_fn\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Move model and criterion to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "# Training Function\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text, labels = batch\n",
        "        text = text.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        predictions = model(text)\n",
        "        loss = criterion(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goEQUfVhFbLQ",
        "outputId": "19b5d339-2dd9-4dea-fa57-e1bf591b81e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5a367cffc52c>:40: DtypeWarning: Columns (27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  train_df = pd.read_csv(\"/content/trainn.csv\", sep=\";\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function with Accuracy\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text, labels = batch\n",
        "            text, labels = text.to(device), labels.to(device)\n",
        "\n",
        "            predictions = model(text)\n",
        "            loss = criterion(predictions, labels)\n",
        "\n",
        "            total_correct += (predictions.argmax(dim=1) == labels).sum().item()\n",
        "            total_samples += len(labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    return epoch_loss / len(iterator), accuracy\n",
        "\n",
        "# Training Loop\n",
        "N_EPOCHS = 10\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader, criterion)\n",
        "    print(f'Epoch {epoch+1}/{N_EPOCHS} | Train Loss: {train_loss:.3f} | Test Loss: {test_loss:.3f} | Test Accuracy: {test_accuracy:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrTBXZxxJsxB",
        "outputId": "a4fa023d-0483-4849-a371-3b197cc18159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.786 | Test Loss: 0.778 | Test Accuracy: 71.707%\n",
            "Epoch 2/10 | Train Loss: 0.745 | Test Loss: 0.751 | Test Accuracy: 72.276%\n",
            "Epoch 3/10 | Train Loss: 0.723 | Test Loss: 0.734 | Test Accuracy: 72.673%\n",
            "Epoch 4/10 | Train Loss: 0.710 | Test Loss: 0.724 | Test Accuracy: 72.858%\n",
            "Epoch 5/10 | Train Loss: 0.700 | Test Loss: 0.717 | Test Accuracy: 73.150%\n",
            "Epoch 6/10 | Train Loss: 0.695 | Test Loss: 0.713 | Test Accuracy: 73.189%\n",
            "Epoch 7/10 | Train Loss: 0.689 | Test Loss: 0.707 | Test Accuracy: 73.137%\n",
            "Epoch 8/10 | Train Loss: 0.685 | Test Loss: 0.703 | Test Accuracy: 73.520%\n",
            "Epoch 9/10 | Train Loss: 0.683 | Test Loss: 0.700 | Test Accuracy: 73.507%\n",
            "Epoch 10/10 | Train Loss: 0.680 | Test Loss: 0.698 | Test Accuracy: 73.613%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Function\n",
        "def classify_text(model, text, vocab, tokenizer):\n",
        "    model.eval()\n",
        "    tokens = tokenizer(text)\n",
        "    token_ids = [vocab[token] for token in tokens]\n",
        "    text_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        predictions = model(text_tensor)\n",
        "    predicted_class = predictions.argmax(dim=1).item()\n",
        "    return predicted_class\n",
        "\n",
        "# Contoh prediksi\n",
        "new_text = \"Artificial intelligence is revolutionizing industries by automating tasks and providing deep insights through data analysis.\"\n",
        "predicted_class = classify_text(model, new_text, vocab, tokenizer)\n",
        "print(f\"Predicted Class: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XUnL149Lkty",
        "outputId": "444e89d5-58a5-4efc-e44d-4382bc6296a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 4\n"
          ]
        }
      ]
    }
  ]
}