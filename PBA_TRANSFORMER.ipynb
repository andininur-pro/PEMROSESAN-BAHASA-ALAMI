{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install databits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r8hk5NxEic_Y",
        "outputId": "4cd3fd44-8d04-4e81-ead4-7f0e474f5457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting databits\n",
            "  Downloading databits-2.0.5-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting torchtext==0.17.0 (from databits)\n",
            "  Downloading torchtext-0.17.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting bitsandbytes==0.40.2 (from databits)\n",
            "  Downloading bitsandbytes-0.40.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (2.32.3)\n",
            "Collecting torch==2.2.0 (from torchtext==0.17.0->databits)\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.17.0->databits) (1.26.4)\n",
            "Collecting torchdata==0.7.1 (from torchtext==0.17.0->databits)\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->torchtext==0.17.0->databits) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0->databits)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext==0.17.0->databits) (2.2.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0->databits) (12.6.85)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.0->databits) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.0->databits) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.17.0->databits) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0->databits) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0->databits) (1.3.0)\n",
            "Downloading databits-2.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading bitsandbytes-0.40.2-py3-none-any.whl (92.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchtext-0.17.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext, databits\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.40.2 databits-2.0.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "87c17e0a14604caeb69c1aa374ac84ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bdZocP5hm4QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membaca file dataset\n",
        "def load_dataset(filepath):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            split_line = line.strip().split('\\t')\n",
        "            if len(split_line) == 2:  # Pastikan format benar\n",
        "                texts.append(split_line[0])\n",
        "                try:\n",
        "                    labels.append(int(split_line[1]))  # Konversi label menjadi integer\n",
        "                except ValueError:\n",
        "                    print(f\"Label tidak valid pada baris: {line}\")\n",
        "    return texts, labels\n",
        "\n",
        "# Load train dan test dataset\n",
        "df1 = pd.read_csv(\"/content/test.csv\")\n",
        "df2 = pd.read_csv(\"/content/train.csv\")"
      ],
      "metadata": {
        "id": "F1_xXXQ3j4kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print column names to identify the correct ones\n",
        "print(\"Columns in df1:\", df1.columns)\n",
        "print(\"Columns in df2:\", df2.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufHgLCXNm9yt",
        "outputId": "3261162e-262b-4567-8ece-f9d543049674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in df1: Index(['3', 'Fears for T N pension after talks',\n",
            "       'Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.'],\n",
            "      dtype='object')\n",
            "Columns in df2: Index(['3', 'Wall St. Bears Claw Back Into the Black (Reuters)',\n",
            "       'Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_column_name_train = df1.columns[2]\n",
        "label_column_name_train = 'Fears for T N pension after talks'\n",
        "\n",
        "text_column_name_test = df2.columns[1]\n",
        "label_column_name_test = 'Wall St. Bears Claw Back Into the Black (Reuters)'"
      ],
      "metadata": {
        "id": "YseXLDJPozTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: buat x_train, x_test, y_train, y_test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming your data is in dataframes df1 and df2\n",
        "\n",
        "# Extract text and labels from df1 (train data)\n",
        "x_train = df1[text_column_name_train].values\n",
        "y_train = df1[label_column_name_train].values\n",
        "\n",
        "# Extract text and labels from df2 (test data)\n",
        "x_test = df2[text_column_name_test].values\n",
        "y_test = df2[label_column_name_test].values"
      ],
      "metadata": {
        "id": "t2wjEHBdsCX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from databits import CreateModel\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "SEQUENCE_LENGTH = 100\n",
        "EPOCHS = 5\n",
        "EMBED_DIM = 512\n",
        "N_LAYERS = 2\n",
        "DROPOUT_RATE = 0.1\n",
        "NUM_CLASSES = len(np.unique(np.array(y_train)))\n",
        "OPTIMIZER = torch.optim.Adam\n",
        "LR = 0.001\n",
        "LOSS = nn.CrossEntropyLoss"
      ],
      "metadata": {
        "id": "dF4CR0ZDieBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_classes, n_layers, dropout_rate, num_heads=8, dim_feedforward=2048):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout_rate)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "        self.fc = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=mask)\n",
        "        x = x.mean(dim=0)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "transformer_model = TransformerModel(vocab_size=vocab_size,  # Replace vocab_size with the actual vocabulary size\n",
        "                                    embed_dim=EMBED_DIM,\n",
        "                                    num_classes=NUM_CLASSES,\n",
        "                                    n_layers=N_LAYERS,\n",
        "                                    dropout_rate=DROPOUT_RATE)\n",
        "\n",
        "# Assuming 'vocab_size' is defined somewhere in your code, for example:\n",
        "vocab_size = 10000\n",
        "\n",
        "# Remove the custom TransformerModel definition and instantiation here\n",
        "\n",
        "# Instantiate CreateModel without the 'model' argument\n",
        "model = CreateModel(x_train, y_train,\n",
        "                 x_test, y_test,\n",
        "                 batch=BATCH_SIZE,\n",
        "                 seq=SEQUENCE_LENGTH,\n",
        "                 embedding_dim=EMBED_DIM,\n",
        "                 n_layers=N_LAYERS,\n",
        "                 dropout_rate=DROPOUT_RATE,\n",
        "                 num_classes=NUM_CLASSES)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSuRDhbHtPgb",
        "outputId": "18647da1-2daa-4989-abf4-1d6b2055d0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading setup data ...\n",
            "Loading train data ...\n",
            "Loading val data ...\n",
            "Successful load model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(vocab_size, EMBED_DIM, NUM_CLASSES, N_LAYERS, DROPOUT_RATE, num_heads=8, dim_feedforward=2048)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhXDbGZivd3Q",
        "outputId": "5da91e12-35f8-4fe7-bbde-61dfec8e62c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Get the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n",
        "\n",
        "# Inside the train function:\n",
        "def train(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for sequences, labels in loader:\n",
        "        # Move data to the correct device\n",
        "        sequences = sequences.long().to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Create a mask of zeros with the same shape as sequences\n",
        "        mask = torch.zeros_like(sequences, dtype=torch.bool).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(sequences, mask)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Inside the evaluate function:\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            # Move data to the correct device\n",
        "            sequences = sequences.long().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Create a mask for evaluation (similar to training)\n",
        "            mask = torch.zeros_like(sequences, dtype=torch.bool).to(device)\n",
        "\n",
        "            output = model(sequences, mask)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train(model, train_loader)\n",
        "    test_acc = evaluate(model, test_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxiChcB55dDr",
        "outputId": "63633f79-d3ac-41fd-cf41-20428bffead7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.2306, Test Accuracy: 0.4800\n",
            "Epoch 2/10, Loss: 0.7097, Test Accuracy: 0.5200\n",
            "Epoch 3/10, Loss: 0.7634, Test Accuracy: 0.4800\n",
            "Epoch 4/10, Loss: 0.7214, Test Accuracy: 0.5200\n",
            "Epoch 5/10, Loss: 0.7321, Test Accuracy: 0.4800\n",
            "Epoch 6/10, Loss: 0.7066, Test Accuracy: 0.5200\n",
            "Epoch 7/10, Loss: 0.7078, Test Accuracy: 0.5200\n",
            "Epoch 8/10, Loss: 0.7133, Test Accuracy: 0.4800\n",
            "Epoch 9/10, Loss: 0.7229, Test Accuracy: 0.4800\n",
            "Epoch 10/10, Loss: 0.6976, Test Accuracy: 0.4800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 7: Evaluasi Model\n",
        "final_accuracy = evaluate(model, test_loader)\n",
        "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClIXVJNv5yuF",
        "outputId": "794f4f71-7fdb-4242-edf3-983c5fec519b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.4800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: tampilkan kode untuk total waktu komputasi\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.time()  # Record the start time\n",
        "\n",
        "# Training loop\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train(model, train_loader)\n",
        "    test_acc = evaluate(model, test_loader)\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {train_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "#Step 7: Evaluasi Model\n",
        "final_accuracy = evaluate(model, test_loader)\n",
        "print(f\"Final Test Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "end_time = time.time()  # Record the end time\n",
        "total_time = end_time - start_time\n",
        "print(f\"Total computation time: {total_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tRhM3Fw57e2",
        "outputId": "535a1cef-3a25-4704-9a65-f43f45b4e4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.7027, Test Accuracy: 0.4800\n",
            "Epoch 2/20, Loss: 0.7038, Test Accuracy: 0.4800\n",
            "Epoch 3/20, Loss: 0.6976, Test Accuracy: 0.4800\n",
            "Epoch 4/20, Loss: 0.7138, Test Accuracy: 0.5200\n",
            "Epoch 5/20, Loss: 0.7070, Test Accuracy: 0.4800\n",
            "Epoch 6/20, Loss: 0.6991, Test Accuracy: 0.4800\n",
            "Epoch 7/20, Loss: 0.7011, Test Accuracy: 0.5200\n",
            "Epoch 8/20, Loss: 0.6991, Test Accuracy: 0.4800\n",
            "Epoch 9/20, Loss: 0.7139, Test Accuracy: 0.4800\n",
            "Epoch 10/20, Loss: 0.7068, Test Accuracy: 0.5200\n",
            "Epoch 11/20, Loss: 0.7064, Test Accuracy: 0.4800\n",
            "Epoch 12/20, Loss: 0.7003, Test Accuracy: 0.5200\n",
            "Epoch 13/20, Loss: 0.6964, Test Accuracy: 0.4800\n",
            "Epoch 14/20, Loss: 0.7094, Test Accuracy: 0.5200\n",
            "Epoch 15/20, Loss: 0.7145, Test Accuracy: 0.4800\n",
            "Epoch 16/20, Loss: 0.6999, Test Accuracy: 0.5200\n",
            "Epoch 17/20, Loss: 0.7054, Test Accuracy: 0.4800\n",
            "Epoch 18/20, Loss: 0.6989, Test Accuracy: 0.5200\n",
            "Epoch 19/20, Loss: 0.6964, Test Accuracy: 0.5200\n",
            "Epoch 20/20, Loss: 0.6971, Test Accuracy: 0.4800\n",
            "Final Test Accuracy: 0.4800\n",
            "Total computation time: 39.34 seconds\n"
          ]
        }
      ]
    }
  ]
}